from fastapi import FastAPI
from transformers import AutoModelForCausalLM, AutoTokenizer
import aio_pika
import asyncio
import json
import re
from pydantic import BaseModel
from pydantic_settings import BaseSettings
import torch
import os
from contextlib import asynccontextmanager

print("CUDA available:", torch.cuda.is_available())
print("GPU count:", torch.cuda.device_count())
print("GPU name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A")

k = 1

class MessageModel(BaseModel):
    prompt: str
    userId: str
    sender: str

class Settings(BaseSettings):
    RABBITMQ_HOST: str = "localhost"
    RABBITMQ_USER: str = "guest"
    RABBITMQ_PASS: str = "guest"

    class Config:
        env_prefix = ""  # å‰ç¶´
        case_sensitive = False # å¤§å°å¯«ä¸æ•æ„Ÿ

class MessageModel(BaseModel):
    prompt: str
    userId: str
    sender: str


app = FastAPI()
settings = Settings()

# æ¨¡å‹åŠ è¼‰
model_path = "./model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto")

login=os.getenv("RABBITMQ_USER", "guest"),
password=os.getenv("RABBITMQ_PASS", "guest"),

# # RabbitMQ é€£æ¥è³‡è¨Š

RABBITMQ_URL = f"amqp://{settings.RABBITMQ_USER}:{settings.RABBITMQ_PASS}@{settings.RABBITMQ_HOST}/"
# RABBITMQ_URL = f"amqp://{login}:{password}@{settings.RABBITMQ_HOST}/"
EXCHANGE_NAME = "chatExchange"  # èˆ‡ Java ä»£ç¢¼ä¸€è‡´
ROUTING_KEY = "private"  # èˆ‡ Java ä»£ç¢¼ä¸€è‡´

# æ¨¡çµ„ç´šåˆ¥åˆå§‹åŒ–ï¼ˆFastAPI å•Ÿå‹•æ™‚åªå»ºç«‹ä¸€æ¬¡ï¼‰
connection: aio_pika.RobustConnection = None
channel: aio_pika.Channel = None
exchange: aio_pika.Exchange = None




@asynccontextmanager
async def lifespan(app: FastAPI):
    global connection, channel, exchange

    # å»ºç«‹é€£ç·š
    connection = await aio_pika.connect_robust(
        RABBITMQ_URL,
        heartbeat=30
    )
    channel = await connection.channel()
    exchange = await channel.declare_exchange(
        EXCHANGE_NAME, aio_pika.ExchangeType.TOPIC, durable=True
    )
    print("RabbitMQ é€£ç·šå·²å•Ÿå‹•")

    yield  # ğŸ‘ˆ åœ¨é€™ä¹‹å¾Œæ‰æœƒåŸ·è¡Œ FastAPI çš„ endpoint

    # â¬‡æ”¶å°¾é—œé–‰é€£ç·š
    await connection.close()
    print("RabbitMQ é€£ç·šå·²é—œé–‰")

# å»ºç«‹ FastAPI å¯¦ä¾‹ï¼Œæ›ä¸Š lifespan
app = FastAPI(lifespan=lifespan)


@app.get('/hi')
async def test():
    return 123
@app.post('/generate')
async def send_to_rabbitmq(data: MessageModel):
    print(f'æ”¶åˆ°{data.prompt}')
    input_text = f"<s>[INST] {data.prompt} [/INST]"
    async def run_generation(prompt: str):
 
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        def do_inference():
            inputs = tokenizer(prompt, return_tensors="pt").to(device)

            outputs = model.generate(
                **inputs,
                max_length=150,
                max_new_tokens=50,
                repetition_penalty=1.2,
                temperature=0.7,
                top_p=0.9,
                do_sample=True
            )
            return tokenizer.decode(outputs[0], skip_special_tokens=True)
      
        return await asyncio.to_thread(do_inference)
    try:
        # å°‡åŒæ­¥æ¨è«–ç§»è‡³èƒŒæ™¯åŸ·è¡Œç·’
        result = await run_generation(input_text)
        match = re.search(r"\[/INST\](.*?)</s>", result)
        extracted_text = match.group(1).strip() if match else "N/A"
        message_body = json.dumps({
            "userId": data.userId,
            "message": extracted_text
        })

        message_obj = aio_pika.Message(
            body=message_body.encode(),
            headers={"userId": data.sender}
        )
        # ç™¼é€çµæœçµ¦ RabbitMQ
        await exchange.publish(message_obj, routing_key=ROUTING_KEY)
        # message = aio_pika.Message(body=result.encode())
        # await exchange.publish(message, routing_key="room.0.answer")

        return {'response': 'ok'}

    except Exception as e:
        print(f"ç™¼é€ RabbitMQ æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {"error": str(e)}
        #     match = re.search(r"\[/INST\](.*?)</s>", response)
        #     extracted_text = match.group(1).strip() if match else "N/A"

        #     message_body = json.dumps({
        #         "userId": data.userId,
        #         "message": extracted_text
        #     })

        #     message_obj = aio_pika.Message(
        #         body=message_body.encode(),
        #         headers={"userId": data.sender}
        #     )

        # await exchange.publish(message_obj, routing_key=ROUTING_KEY)

        # return {'response': 'ok'}

    # except aio_pika.exceptions.AMQPConnectionError as e:
    #     print("RabbitMQ é€£ç·šä¸­æ–·:", e)
    #     return {"error": "connection_reset", "detail": str(e)}
    # except Exception as e:
    #     print("ç™¼é€æ™‚ç™¼ç”ŸéŒ¯èª¤:", e)
    #     return {"error": "unexpected", "detail": str(e)}

# @app.post('/generate')
# async def send_to_rabbitmq(data: MessageModel):
#     print(f'æ”¶åˆ°{data.prompt}')
#     """å°‡ LLM ç”Ÿæˆçš„çµæœç™¼é€åˆ° RabbitMQï¼Œä¸¦è¨­ç½® exchange å’Œ routing_key"""
#     connection = await aio_pika.connect_robust(RABBITMQ_URL)
#     async with connection:
#         channel = await connection.channel()

#         # ç¢ºä¿äº¤æ›æ©Ÿå·²å®£å‘Š (é¡å‹èˆ‡ Java ä¸€è‡´)
#         exchange = await channel.declare_exchange(EXCHANGE_NAME, aio_pika.ExchangeType.TOPIC, durable=True)
#         input_text = f"<s>[INST] {data.prompt} [/INST]"
#         # å‰µå»ºæ¶ˆæ¯ï¼Œä¸¦é™„å¸¶ headers
#         device = "cuda" if torch.cuda.is_available() else "cpu"
#         print(device)
#         inputs = tokenizer(input_text, return_tensors="pt").to(device)
      
#         outputs = model.generate(
#             **inputs,
#             max_length=150,  # é™åˆ¶ç¸½é•·åº¦
#             max_new_tokens=50,  # é™åˆ¶æ¨¡å‹æ–°å¢çš„ token æ•¸é‡
#             repetition_penalty=1.2,  # æ¸›å°‘é‡è¤‡å›æ‡‰
#             temperature=0.7,  # æ§åˆ¶éš¨æ©Ÿæ€§
#             top_p=0.9,  # éæ¿¾ä½æ©Ÿç‡è©
#             do_sample=True  # å•Ÿç”¨éš¨æ©Ÿæ¡æ¨£
#         )
#         response = tokenizer.decode(outputs[0], skip_special_tokens=True)
#         pattern = r"\[/INST\](.*?)</s>"

#         match = re.search(pattern, response)
#         if match:
#             extracted_text = match.group(1).strip()  # æå–åŒ¹é…çš„å…§å®¹ä¸¦å»é™¤å‰å¾Œç©ºç™½
#             print("æå–çš„æ–‡å­—:", extracted_text)
#         else:
#             print("æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡å­—")
#         message_data = {
#             "userId": data.userId,
#             "message": extracted_text
#         }
       
#         # è½‰æ›æˆ JSON
#         message_body = json.dumps(message_data)
#         message_obj = aio_pika.Message(
#             body=message_body.encode(),
#             headers={"userId": data.sender}
#         )
#         # ç™¼é€æ¶ˆæ¯åˆ°æŒ‡å®šçš„ exchange å’Œ routing key
#         await exchange.publish(message_obj, routing_key=ROUTING_KEY)

#         return {'response':'ok'}